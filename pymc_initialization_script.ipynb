{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "69aa709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTENSOR_FLAGS'] = 'mode=FAST_COMPILE,optimizer=fast_compile,floatX=float32,cxx='\n",
    "\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b63f0",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate the initialization capability of PyMC's ADVI.\n",
    "\n",
    "We will fit a simple 1d normal distribution using ADVI and compare the initializations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a7a5c594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567a6b6b3a554fdeba536a00df509594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba477c624164296bbdcc9739cae53b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    }
   ],
   "source": [
    "init_mean = 0.2\n",
    "with pm.Model() as init_model:\n",
    "    # Define priors\n",
    "    mu = pm.Normal(\"mu\", 0, 1)\n",
    "    likelihood = pm.Normal('y', mu=mu, sigma=1, observed=None)\n",
    "    advi = pm.ADVI(start={'mu': init_mean})\n",
    "    init_fit = advi.fit(0)\n",
    "\n",
    "with pm.Model() as default_model:\n",
    "    # Define priors\n",
    "    mu = pm.Normal(\"mu\", 0, 1)\n",
    "    likelihood = pm.Normal('y', mu=mu, sigma=1, observed=None)\n",
    "    default_fit = pm.fit(0, method=pm.ADVI())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "45b3202d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we figure out which index mu is - just to make sure we are looking at the correct value\n",
    "default_mu_idx = [var.name for var in default_model.unobserved_RVs].index(\"mu\")\n",
    "init_mu_idx = [var.name for var in init_model.unobserved_RVs].index(\"mu\")\n",
    "default_mu_idx, init_mu_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "dff2c773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(0.0), np.float32(0.6931472))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what the default initialized to\n",
    "default_fit.mean.eval()[default_mu_idx], default_fit.std.eval()[default_mu_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e99e96d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float32(0.2), np.float32(0.6931472))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what the init initialized to, \n",
    "# when we told it to use start={'mu': 1.0}\n",
    "init_fit.mean.eval()[init_mu_idx], init_fit.std.eval()[init_mu_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721edbc",
   "metadata": {},
   "source": [
    "Now, let's use a Beta model to determine whether this initialization is changing the constrained value in $(0, 1)$ or unconstrained mean in $\\mathbb{R}$.\n",
    "\n",
    "We will sample from the posterior and take the empirical mean and std and compare it to the initial parameter value of $0.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea491be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b9700b2a9e4158bc7433f3a0ee0f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    }
   ],
   "source": [
    "init_mean = 0.2\n",
    "with pm.Model() as beta_model:\n",
    "    # Define priors\n",
    "    theta = pm.Beta(\"theta\", 2, 5)\n",
    "    likelihood = pm.Binomial('obs', n=10, p=theta, observed=2)\n",
    "    advi = pm.ADVI(start={'theta': init_mean})\n",
    "    approx = advi.fit(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4ef0d",
   "metadata": {},
   "source": [
    "Let's look at what samples from the posterior give us empirically for the constrained mean and std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7ce86ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior samples (constrained theta):\n",
      "  mean = 0.22040887 std = 0.11290903\n",
      "\n",
      "Unconstrained (R) params for theta after initialization:\n",
      "  mu_z    = -1.3862944\n",
      "  sigma_z = 0.6931471824645996\n",
      "\n",
      "MC from z-space params (should match approx.sample mean):\n",
      "  mean = 0.22057717815746278 std = 0.11323499329891867\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idata = approx.sample(100_000, random_seed=0)\n",
    "theta_samps = np.asarray(idata.posterior[\"theta\"]).ravel()\n",
    "print(\"Posterior samples (constrained theta):\")\n",
    "print(\"  mean =\", theta_samps.mean(), \"std =\", theta_samps.std(ddof=1))\n",
    "\n",
    "# ADVI mean-field uses 'mu' and 'rho' (rho -> sigma via softplus) in *unconstrained space*.\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "rho = approx.params_dict.get(\"rho\")\n",
    "\n",
    "mu_z = mu[0].eval()\n",
    "sigma_z = float(np.log1p(np.exp(rho[0].eval())))  # softplus(rho)\n",
    "\n",
    "print(\"\\nUnconstrained (R) params for theta after initialization:\")\n",
    "print(\"  mu_z    =\", mu_z)\n",
    "print(\"  sigma_z =\", sigma_z)\n",
    "\n",
    "# Let's take samples in unconstrained space and transform them to constrained space to verify the empirical mean/std\n",
    "eps = np.random.randn(200_000)\n",
    "theta_mc = 1.0 / (1.0 + np.exp(-(mu_z + sigma_z * eps)))\n",
    "print(\"\\nMC from z-space params (should match approx.sample mean):\")\n",
    "print(\"  mean =\", theta_mc.mean(), \"std =\", theta_mc.std(ddof=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e4e44",
   "metadata": {},
   "source": [
    "Since the posterior samples and MC samples have matching summary statistics, we can see that measure-transport like we just performed is what is happening under the hood when the \"constrained mean\" is initialized."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env_pm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
