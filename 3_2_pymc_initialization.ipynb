{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69aa709a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTENSOR_FLAGS'] = 'mode=FAST_COMPILE,optimizer=fast_compile,floatX=float32,cxx='\n",
    "\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "import pytensor.tensor as pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec3b63f0",
   "metadata": {},
   "source": [
    "In this notebook, we demonstrate the initialization capability of PyMC's ADVI.\n",
    "\n",
    "We will fit a simple 1d normal distribution using ADVI and compare the initializations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbc5f2d",
   "metadata": {},
   "source": [
    "Specifically, we will answer the following questions.\n",
    "\n",
    "1. For unknown parameters in the likelihood, what does PyMC assign as the starting unconstrained mean $\\tilde{\\mu}$?\n",
    "    - What is this value by default?\n",
    "    - How is this value impacted by our input?\n",
    "\n",
    "We will begin by looking at a Normal-Normal model and a beta-binomial model. In the normal case, no transformation is required so we expect that $\\tilde{\\mu}$ is equal to the input starting value. In the beta-binomial case, we know that PyMC uses a sigmoid transformation to move from $\\mathbb{R}$ to $(0, 1)$, so we expect that $\\tilde{\\mu}$ is equal to the logit of the input starting value (since the starting value is input *in the constrained space*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7a5c594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa85e268fbdd48a2b4ab437020b5286a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b48ba8b081f4f1b8297dc5a8f0416b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default initialization is: [0.], [0.6931472]\n",
      "Manual initialization is: [0.2], [0.6931472]\n"
     ]
    }
   ],
   "source": [
    "init_mean = 0.2\n",
    "with pm.Model() as init_model:\n",
    "    mu = pm.Normal(\"mu\", 0, 1)\n",
    "    likelihood = pm.Normal('y', mu=mu, sigma=1, observed=1)\n",
    "    advi = pm.ADVI(start={'mu': init_mean})\n",
    "    init_fit = advi.fit(0)\n",
    "\n",
    "with pm.Model() as default_model:\n",
    "    mu = pm.Normal(\"mu\", 0, 1)\n",
    "    likelihood = pm.Normal('y', mu=mu, sigma=1, observed=1)\n",
    "    advi = pm.ADVI()\n",
    "    default_fit = advi.fit(0)\n",
    "\n",
    "# This is what \\tilde{\\mu} and \\tilde{\\sigma} are from the default and our input\n",
    "print(f\"Default initialization is: {default_fit.mean.eval()}, {default_fit.std.eval()}\")\n",
    "print(f\"Manual initialization is: {init_fit.mean.eval()}, {init_fit.std.eval()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2721edbc",
   "metadata": {},
   "source": [
    "Now, let's use a Beta model, as an example of when a transformation is required, to determine whether manual initialization is changing the constrained value in $(0, 1)$ or unconstrained mean in $\\mathbb{R}$.\n",
    "\n",
    "When we give PyMC a starting value $x$ for a parameter $\\theta$ where PyMC uses transformation $T$ to transform from $\\mathbb{R}$ to the support of $\\theta$, PyMC sets the unconstrained mean $\\tilde{\\mu}$ (of the underlying normal distribution used in ADVI) to $T^{-1}(x)$.\n",
    "\n",
    "To examine this functionality, we will sample from the posterior and take the empirical mean and std of posterior samples to compare to the starting value choice for $\\theta$ of $0.2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea491be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96e16153b69451680e515535e0daffa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.3862943611198906\n",
      "[-1.3862944]\n",
      "[theta]\n"
     ]
    }
   ],
   "source": [
    "init_mean = 0.2\n",
    "with pm.Model() as beta_model:\n",
    "    # Define priors\n",
    "    theta = pm.Beta(\"theta\", 2, 5)\n",
    "    likelihood = pm.Binomial('obs', n=10, p=theta, observed=2)\n",
    "    advi = pm.ADVI(start={'theta': init_mean})\n",
    "    approx = advi.fit(0)\n",
    "\n",
    "# check if mu = approx.params_dict.get(\"mu\") is equal to logit(init_mean)\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "logit_mu = np.log(init_mean / (1 - init_mean))\n",
    "print(logit_mu)\n",
    "print(mu.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417cdc80",
   "metadata": {},
   "source": [
    "Now, we'd like to understand what is happening with a possibly more contrived example.\n",
    "\n",
    "Again, we'd like to understand what PyMC sets as $\\tilde{\\mu}$ by default and when we manually change the starting value.\n",
    "\n",
    "When we put 'None' as the observed= values of the likelihood distribution, PyMC treats it as a free RV and we may directly access the underlying starting values for the unknown parameters in the likelihood.\n",
    "\n",
    "First, we look at the case where $X$~$\\mathcal{N}(1, 3) * 2$ and $Y$~$\\mathcal{N}(X, 1)$.\n",
    "\n",
    "Note that we use pm.Deterministic so that everything plays nice in PyMC's code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a67716e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28b484741aac47a78ad699426d273101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 4.]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as weird_model:\n",
    "    # Define priors\n",
    "    x_sub = pm.Normal(\"x_sub\", 2, 3)\n",
    "    x = pm.Deterministic(\"x\", x_sub * 2)\n",
    "    likelihood = pm.Normal('y', mu=x, sigma=1, observed=None)\n",
    "    advi = pm.ADVI()\n",
    "    approx = advi.fit(0)\n",
    "\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "print(mu.eval())\n",
    "# this returns the initial value of the tilde{mu} of x_sub and the initial value of the tilde{mu} of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb126432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc71cd334c94201b04cbf15a3cad8c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10. 20.]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as weird_model:\n",
    "    # Define priors\n",
    "    x_sub = pm.Normal(\"x_sub\", 2, 3)\n",
    "    x = pm.Deterministic(\"x\", x_sub * 2)\n",
    "    likelihood = pm.Normal('y', mu=x, sigma=1, observed=None)\n",
    "    advi = pm.ADVI(start={'x_sub': 10}) # we may change either x_sub or x here but only x_sub actually changes the start point of y!\n",
    "    approx = advi.fit(0)\n",
    "\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "print(mu.eval())\n",
    "# this returns the initial value of the tilde{mu} of x_sub and the initial value of the tilde{mu} of y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a49d0adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a4f753d76c41e7a807f3d3a30f371c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 4.]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as weird_model:\n",
    "    # Define priors\n",
    "    x_sub = pm.Normal(\"x_sub\", 2, 3)\n",
    "    x = pm.Deterministic(\"x\", x_sub * 2)\n",
    "    likelihood = pm.Normal('y', mu=x, sigma=1, observed=None)\n",
    "    advi = pm.ADVI(start={'x': 10}) # we may change either x_sub or x here!\n",
    "    approx = advi.fit(0)\n",
    "\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "print(mu.eval())\n",
    "# this returns the initial value of the tilde{mu} of x_sub and the initial value of the tilde{mu} of y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a45f6",
   "metadata": {},
   "source": [
    "Now let's look at another weird prior:\n",
    "$X$~Uniform$(-3, 3) + 10$ and $Y$~$\\mathcal{N}(X, 1)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "73210772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3129e66102e74e6e933f23c369d61bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. 10.]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as weird_model:\n",
    "    # Define priors\n",
    "    uni = pm.Uniform(\"uni_sub\", -3, 3)\n",
    "    uni_2 = pm.Deterministic(\"uni_2\", uni + 10)\n",
    "    likelihood = pm.Normal('y', mu=uni_2, sigma=1, observed=None)\n",
    "    advi = pm.ADVI()\n",
    "    approx = advi.fit(0)\n",
    "\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "print(mu.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b712f177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf685fdcb1e941fe9d9a59c913bcf26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. 10.]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as weird_model:\n",
    "    # Define priors\n",
    "    uni = pm.Uniform(\"uni_sub\", -3, 3)\n",
    "    uni_2 = pm.Deterministic(\"uni_2\", uni + 10)\n",
    "    likelihood = pm.Normal('y', mu=uni_2, sigma=1, observed=None)\n",
    "    advi = pm.ADVI(start={'uni_2': 10.5})  # again, only changing uni_sub actually changes the initial values\n",
    "    approx = advi.fit(0)\n",
    "\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "print(mu.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0172c28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585c9211d81b43709b4a761dfd61e09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.33647215 10.5       ]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as weird_model:\n",
    "    # Define priors\n",
    "    uni = pm.Uniform(\"uni_sub\", -3, 3)\n",
    "    uni_2 = pm.Deterministic(\"uni_2\", uni + 10)\n",
    "    likelihood = pm.Normal('y', mu=uni_2, sigma=1, observed=None)\n",
    "    advi = pm.ADVI(start={'uni_sub': 0.5})  # again, only changing uni_sub actually changes the initial values\n",
    "    approx = advi.fit(0)\n",
    "\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "print(mu.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7652a592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/madelynandersen/miniconda3/envs/pymc_env_pm/lib/python3.11/site-packages/pytensor/tensor/elemwise.py:710: RuntimeWarning: invalid value encountered in log\n",
      "  variables = ufunc(*ufunc_args, **ufunc_kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b7ae37b614409caa6bf3251affa62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initialization only\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan nan]\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as weird_model:\n",
    "    # Define priors\n",
    "    uni = pm.Uniform(\"uni_sub\", -3, 3)\n",
    "    uni_2 = pm.Deterministic(\"uni_2\", uni + 10)\n",
    "    likelihood = pm.Normal('y', mu=uni_2, sigma=1, observed=None)\n",
    "    advi = pm.ADVI(start={'uni_sub': 10.5})  # can we initialize out of support?\n",
    "    approx = advi.fit(0)\n",
    "\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "print(mu.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f4ef0d",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "Let's look at what samples from the posterior give us empirically for the constrained mean and std of the posterior of $\\theta$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ce86ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posterior samples (constrained theta):\n",
      "  mean = 0.2204934 std = 0.1132369\n",
      "\n",
      "Unconstrained (R) params for theta after initialization:\n",
      "  mu_z    = -1.3862944\n",
      "  sigma_z = 0.6931471824645996\n",
      "\n",
      "MC from z-space params (should match approx.sample mean):\n",
      "  mean = 0.2208659595507493 std = 0.11344936075158488\n"
     ]
    }
   ],
   "source": [
    "\n",
    "idata = approx.sample(1_000_000, random_seed=0)\n",
    "theta_samps = np.asarray(idata.posterior[\"theta\"]).ravel()\n",
    "print(\"Posterior samples (constrained theta):\")\n",
    "print(\"  mean =\", theta_samps.mean(), \"std =\", theta_samps.std(ddof=1))\n",
    "\n",
    "# ADVI mean-field uses 'mu' and 'rho' (rho -> sigma via softplus) in *unconstrained space*.\n",
    "mu = approx.params_dict.get(\"mu\")\n",
    "rho = approx.params_dict.get(\"rho\")\n",
    "\n",
    "mu_z = mu[0].eval()\n",
    "sigma_z = float(np.log1p(np.exp(rho[0].eval())))  # softplus(rho)\n",
    "\n",
    "print(\"\\nUnconstrained (R) params for theta after initialization:\")\n",
    "print(\"  mu_z    =\", mu_z)\n",
    "print(\"  sigma_z =\", sigma_z)\n",
    "\n",
    "# Let's take samples in unconstrained space and transform them to constrained space to verify the empirical mean/std\n",
    "# sample from N(mu_z, sigma_z^2)\n",
    "from scipy.stats import norm\n",
    "unconstrained_samples = norm.rvs(loc=mu_z, scale=sigma_z, size=1_000_000, random_state=0)\n",
    "# transform that to (0, 1) via sigmoid transformation\n",
    "mc_samples = 1.0 / (1.0 + np.exp(-unconstrained_samples))\n",
    "print(\"\\nMC from z-space params (should match approx.sample mean):\")\n",
    "print(\"  mean =\", mc_samples.mean(), \"std =\", mc_samples.std(ddof=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28e4e44",
   "metadata": {},
   "source": [
    "Since the posterior samples and MC samples have matching summary statistics, we can see that measure-transport like we just performed is what is happening under the hood when the \"constrained mean\" is initialized."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env_pm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
