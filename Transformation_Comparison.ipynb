{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Transformation Comparison: Default vs Manual\n",
        "\n",
        "This notebook demonstrates a case where NumPyro's default transformation (softplus) is outperformed by a manually chosen transformation (exp) for small positive parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running SVI with different transformations...\n",
            "Step 0: Softplus=288.345947, Exp=4997.666016, Custom=11260.791992\n",
            "Step 200: Softplus=29.039198, Exp=531.310547, Custom=269.575958\n",
            "Step 400: Softplus=12.312260, Exp=213.392532, Custom=100.111549\n",
            "Step 600: Softplus=7.708896, Exp=117.829994, Custom=65.084518\n",
            "Step 800: Softplus=5.404984, Exp=75.140633, Custom=37.067211\n"
          ]
        }
      ],
      "source": [
        "# Let's create a case where manual transformation clearly outperforms default\n",
        "import numpy as np\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpyro\n",
        "import numpyro.distributions as dist\n",
        "from numpyro.infer import SVI, Trace_ELBO\n",
        "from numpyro.optim import Adam\n",
        "from numpyro.infer.autoguide import AutoNormal\n",
        "\n",
        "# print(\"=== CASE WHERE MANUAL TRANSFORMATION WINS ===\")\n",
        "# print(\"Model: z ~ N(0,1), y|z ~ N(z, σ), y=1.0, σ ~ HalfNormal(0.01)\")\n",
        "# print(\"True σ = 0.01 (very small positive value)\")\n",
        "# print()\n",
        "\n",
        "# Model with very small positive parameter\n",
        "def model(y):\n",
        "    z = numpyro.sample('z', dist.Normal(0., 1.))\n",
        "    sigma = numpyro.sample('sigma', dist.HalfNormal(0.01))  # Very small sigma\n",
        "    numpyro.sample('y', dist.Normal(z, sigma), obs=y)\n",
        "\n",
        "# default transformation\n",
        "def guide_softplus(y):\n",
        "    z_loc = numpyro.param('z_loc', 0.0)\n",
        "    z_scale = numpyro.param('z_scale', 1.0, constraint=dist.constraints.positive)\n",
        "    numpyro.sample('z', dist.Normal(z_loc, z_scale))\n",
        "    \n",
        "    sigma_unconstrained = numpyro.param('sigma_softplus', 0.0)\n",
        "    sigma = jax.nn.softplus(sigma_unconstrained)\n",
        "    numpyro.sample('sigma', dist.Delta(sigma))\n",
        "\n",
        "guide_softplus = AutoNormal(model)\n",
        "\n",
        "# Guide with exp (manual) - should work better for very small values\n",
        "def guide_exp(y):\n",
        "    z_loc = numpyro.param('z_loc', 0.0)\n",
        "    z_scale = numpyro.param('z_scale', 1.0, constraint=dist.constraints.positive)\n",
        "    numpyro.sample('z', dist.Normal(z_loc, z_scale))\n",
        "    \n",
        "    sigma_unconstrained = numpyro.param('sigma_exp', 0.0)\n",
        "    sigma = jnp.exp(sigma_unconstrained)\n",
        "    numpyro.sample('sigma', dist.Delta(sigma))\n",
        "\n",
        "# Guide with custom transformation for very small values\n",
        "def guide_custom(y):\n",
        "    z_loc = numpyro.param('z_loc', 0.0)\n",
        "    z_scale = numpyro.param('z_scale', 1.0, constraint=dist.constraints.positive)\n",
        "    numpyro.sample('z', dist.Normal(z_loc, z_scale))\n",
        "    \n",
        "    # Custom: sigma = 0.01 * exp(x) - this centers the transformation around 0.01\n",
        "    sigma_unconstrained = numpyro.param('sigma_custom', 0.0)\n",
        "    sigma = 0.01 * jnp.exp(sigma_unconstrained)\n",
        "    numpyro.sample('sigma', dist.Delta(sigma))\n",
        "\n",
        "# Run optimization\n",
        "elbo = Trace_ELBO(num_particles=100)\n",
        "optimizer = Adam(1e-2)\n",
        "\n",
        "print(\"Running SVI with different transformations...\")\n",
        "svi_softplus = SVI(model, guide_softplus, optimizer, elbo)\n",
        "svi_exp = SVI(model, guide_exp, optimizer, elbo)\n",
        "svi_custom = SVI(model, guide_custom, optimizer, elbo)\n",
        "\n",
        "state_softplus = svi_softplus.init(jax.random.PRNGKey(42), y=jnp.array(1.0))\n",
        "state_exp = svi_exp.init(jax.random.PRNGKey(42), y=jnp.array(1.0))\n",
        "state_custom = svi_custom.init(jax.random.PRNGKey(42), y=jnp.array(1.0))\n",
        "\n",
        "# Run for 1000 steps\n",
        "for i in range(1000):\n",
        "    state_softplus, loss_softplus = svi_softplus.update(state_softplus, y=jnp.array(1.0))\n",
        "    state_exp, loss_exp = svi_exp.update(state_exp, y=jnp.array(1.0))\n",
        "    state_custom, loss_custom = svi_custom.update(state_custom, y=jnp.array(1.0))\n",
        "    \n",
        "    if i % 200 == 0:\n",
        "        print(f\"Step {i}: Softplus={loss_softplus:.6f}, Exp={loss_exp:.6f}, Custom={loss_custom:.6f}\")\n",
        "\n",
        "# Check learned parameters\n",
        "params_softplus = svi_softplus.get_params(state_softplus)\n",
        "params_exp = svi_exp.get_params(state_exp)\n",
        "params_custom = svi_custom.get_params(state_custom)\n",
        "# print(params_softplus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\\nLearned sigma values:\n",
            "Softplus: 0.023971\n",
            "Exp:      0.104820\n",
            "Custom:   0.029475\n",
            "True:     0.01\n"
          ]
        }
      ],
      "source": [
        "\n",
        "sigma_softplus = jax.nn.softplus(params_softplus['sigma_auto_loc'])\n",
        "sigma_exp = jnp.exp(params_exp['sigma_exp'])\n",
        "sigma_custom = 0.01 * jnp.exp(params_custom['sigma_custom'])\n",
        "\n",
        "print(\"\\\\nLearned sigma values:\")\n",
        "print(f\"Softplus: {sigma_softplus:.6f}\")\n",
        "print(f\"Exp:      {sigma_exp:.6f}\")\n",
        "print(f\"Custom:   {sigma_custom:.6f}\")\n",
        "print(f\"True:     0.01\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running SVI with different transformations...\n",
            "\\nFinal Results:\n",
            "Softplus final loss: 2.080383\n",
            "Exp final loss:      -2.773820\n",
            "Custom final loss:   -2.488031\n",
            "\\nLearned sigma values:\n",
            "Softplus: 0.008191\n",
            "Exp:      0.006041\n",
            "Custom:   0.008955\n",
            "True:     0.01\n"
          ]
        }
      ],
      "source": [
        "# now we run and collect tracking values\n",
        "# default transformation\n",
        "guide_softplus = AutoNormal(model)\n",
        "\n",
        "# Guide with exp (manual) - should work better for very small values\n",
        "def guide_exp(y):\n",
        "    z_loc = numpyro.param('z_loc', 0.0)\n",
        "    z_scale = numpyro.param('z_scale', 1.0, constraint=dist.constraints.positive)\n",
        "    numpyro.sample('z', dist.Normal(z_loc, z_scale))\n",
        "    \n",
        "    sigma_unconstrained = numpyro.param('sigma_exp', 0.0)\n",
        "    sigma = jnp.exp(sigma_unconstrained)\n",
        "    numpyro.sample('sigma', dist.Delta(sigma))\n",
        "\n",
        "# Guide with custom transformation for very small values\n",
        "def guide_custom(y):\n",
        "    z_loc = numpyro.param('z_loc', 0.0)\n",
        "    z_scale = numpyro.param('z_scale', 1.0, constraint=dist.constraints.positive)\n",
        "    numpyro.sample('z', dist.Normal(z_loc, z_scale))\n",
        "    \n",
        "    # Custom: sigma = 0.01 * exp(x) - this centers the transformation around 0.01\n",
        "    sigma_unconstrained = numpyro.param('sigma_custom', 0.0)\n",
        "    sigma = 0.01 * jnp.exp(sigma_unconstrained)\n",
        "    numpyro.sample('sigma', dist.Delta(sigma))\n",
        "\n",
        "# Run optimization and collect intermediate results\n",
        "elbo = Trace_ELBO(num_particles=100)\n",
        "optimizer = Adam(1e-2)\n",
        "\n",
        "print(\"Running SVI with different transformations...\")\n",
        "svi_softplus = SVI(model, guide_softplus, optimizer, elbo)\n",
        "svi_exp = SVI(model, guide_exp, optimizer, elbo)\n",
        "svi_custom = SVI(model, guide_custom, optimizer, elbo)\n",
        "\n",
        "state_softplus = svi_softplus.init(jax.random.PRNGKey(42), y=jnp.array(1.0))\n",
        "state_exp = svi_exp.init(jax.random.PRNGKey(42), y=jnp.array(1.0))\n",
        "state_custom = svi_custom.init(jax.random.PRNGKey(42), y=jnp.array(1.0))\n",
        "\n",
        "# Store results for plotting\n",
        "results = {\n",
        "    'softplus': {'losses': [], 'z_locs': [], 'z_scales': [], 'sigmas': []},\n",
        "    'exp': {'losses': [], 'z_locs': [], 'z_scales': [], 'sigmas': []},\n",
        "    'custom': {'losses': [], 'z_locs': [], 'z_scales': [], 'sigmas': []}\n",
        "}\n",
        "\n",
        "# Run for 10,000 steps and collect data\n",
        "for i in range(10000):\n",
        "    state_softplus, loss_softplus = svi_softplus.update(state_softplus, y=jnp.array(1.0))\n",
        "    state_exp, loss_exp = svi_exp.update(state_exp, y=jnp.array(1.0))\n",
        "    state_custom, loss_custom = svi_custom.update(state_custom, y=jnp.array(1.0))\n",
        "    \n",
        "    if i % 200 == 0:  # Collect data every 200 steps\n",
        "        # Get parameters\n",
        "        params_softplus = svi_softplus.get_params(state_softplus)\n",
        "        params_exp = svi_exp.get_params(state_exp)\n",
        "        params_custom = svi_custom.get_params(state_custom)\n",
        "        \n",
        "        # Store results\n",
        "        results['softplus']['losses'].append(loss_softplus)\n",
        "        results['softplus']['z_locs'].append(float(params_softplus['z_auto_loc']))\n",
        "        results['softplus']['z_scales'].append(float(params_softplus['z_auto_scale']))\n",
        "        results['softplus']['sigmas'].append(float(jax.nn.softplus(params_softplus['sigma_auto_loc'])))\n",
        "        \n",
        "        results['exp']['losses'].append(loss_exp)\n",
        "        results['exp']['z_locs'].append(float(params_exp['z_loc']))\n",
        "        results['exp']['z_scales'].append(float(params_exp['z_scale']))\n",
        "        results['exp']['sigmas'].append(float(jnp.exp(params_exp['sigma_exp'])))\n",
        "        \n",
        "        results['custom']['losses'].append(loss_custom)\n",
        "        results['custom']['z_locs'].append(float(params_custom['z_loc']))\n",
        "        results['custom']['z_scales'].append(float(params_custom['z_scale']))\n",
        "        results['custom']['sigmas'].append(float(0.01 * jnp.exp(params_custom['sigma_custom'])))\n",
        "\n",
        "print(\"\\\\nFinal Results:\")\n",
        "print(f\"Softplus final loss: {results['softplus']['losses'][-1]:.6f}\")\n",
        "print(f\"Exp final loss:      {results['exp']['losses'][-1]:.6f}\")\n",
        "print(f\"Custom final loss:   {results['custom']['losses'][-1]:.6f}\")\n",
        "\n",
        "print(\"\\\\nLearned sigma values:\")\n",
        "print(f\"Softplus: {results['softplus']['sigmas'][-1]:.6f}\")\n",
        "print(f\"Exp:      {results['exp']['sigmas'][-1]:.6f}\")\n",
        "print(f\"Custom:   {results['custom']['sigmas'][-1]:.6f}\")\n",
        "print(f\"True:     0.01\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create comprehensive plots\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m fig, axes = \u001b[43mplt\u001b[49m.subplots(\u001b[32m2\u001b[39m, \u001b[32m1\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m10\u001b[39m))\n\u001b[32m      3\u001b[39m fig.suptitle(\u001b[33m'\u001b[39m\u001b[33mTransformation Comparison: Posterior Convergence\u001b[39m\u001b[33m'\u001b[39m, fontsize=\u001b[32m16\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Convert to numpy arrays for plotting\u001b[39;00m\n",
            "\u001b[31mNameError\u001b[39m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# Create comprehensive plots\n",
        "fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
        "fig.suptitle('Transformation Comparison: Posterior Convergence', fontsize=16)\n",
        "\n",
        "# Convert to numpy arrays for plotting\n",
        "steps = np.arange(0, 10000, 200)\n",
        "\n",
        "\n",
        "# Plot 1: Sigma parameter convergence\n",
        "axes[0].plot(steps, results['softplus']['sigmas'], label='Softplus', linewidth=2)\n",
        "axes[0].plot(steps, results['exp']['sigmas'], label='Exp', linewidth=2)\n",
        "axes[0].plot(steps, results['custom']['sigmas'], label='Custom', linewidth=2, color='purple')\n",
        "axes[0].axhline(y=0.01, color='red', linestyle='--', label='True σ=0.01', linewidth=2)\n",
        "axes[0].set_xlabel('Optimization Steps')\n",
        "axes[0].set_ylabel('Learned σ')\n",
        "axes[0].set_title('σ Parameter Convergence')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "# Plot 5: Final posterior distributions for z\n",
        "z_range = np.linspace(0, 2, 1000)\n",
        "for i, (name, color) in enumerate([('softplus', 'blue'), ('exp', 'green'), ('custom', 'purple')]):\n",
        "    z_loc = results[name]['z_locs'][-1]\n",
        "    z_scale = results[name]['z_scales'][-1]\n",
        "    z_pdf = (1/(z_scale * np.sqrt(2*np.pi))) * np.exp(-0.5 * ((z_range - z_loc)/z_scale)**2)\n",
        "    axes[1].plot(z_range, z_pdf, label=f'{name.capitalize()}', color=color, linewidth=2)\n",
        "\n",
        "# True posterior (approximate)\n",
        "true_z_loc = 1.0  # Approximate true posterior mean\n",
        "true_z_scale = 0.01  # Approximate true posterior std\n",
        "true_z_pdf = (1/(true_z_scale * np.sqrt(2*np.pi))) * np.exp(-0.5 * ((z_range - true_z_loc)/true_z_scale)**2)\n",
        "axes[1].plot(z_range, true_z_pdf, label='True Posterior', color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
        "\n",
        "axes[1].set_xlabel('z')\n",
        "axes[1].set_ylabel('Density')\n",
        "axes[1].set_title('Final Z Posterior Distributions')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].set_xlim(0.9, 1.1)\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\\\nVisual Analysis:\")\n",
        "print(\"1. Loss convergence shows which transformation optimizes fastest\")\n",
        "print(\"2. σ parameter convergence shows which gets closest to true value (0.01)\")\n",
        "print(\"3. Z posterior distributions show the quality of the learned approximation\")\n",
        "print(\"4. The custom transformation should show better convergence to the true σ value\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tfp_2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
